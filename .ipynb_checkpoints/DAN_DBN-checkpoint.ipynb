{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf #Deep learning Library\n",
    "import numpy as np #Matrix Algebra Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting the MNIST data provided by Tensorflow\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#Loading in the mnist data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images,\\\n",
    "    mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RBM_DAN(object):\n",
    "    def __init__(self, input_size, output_size, learning_rate, batch_size):\n",
    "        self.input_size = input_size #Size of the input layer\n",
    "        self.output_size = output_size #Size of the hidden layer\n",
    "        self.epochs = 5 #How many times we will update the weights \n",
    "        self.learning_rate = learning_rate #How big of a weight update we will perform \n",
    "        self.batch_size = batch_size #How many images will we \"feature engineer\" at at time \n",
    "        self.new_input_layer = None #Initalize new input layer variable for k-step contrastive divergence \n",
    "        self.new_hidden_layer = None\n",
    "        self.new_test_hidden_layer = None\n",
    "        \n",
    "        #Here we initialize the weights and biases of our RBM\n",
    "        #If you are wondering, the 0 is the mean of the distribution we are getting our random weights from. \n",
    "        #The .01 is the standard deviation.\n",
    "        self.w = np.random.normal(0,0.01,[input_size,output_size]) #weights\n",
    "        self.hb = np.random.normal(0,0.01,[output_size]) #hidden layer bias\n",
    "        self.vb = np.random.normal(0,0.01,[input_size]) #input layer bias (sometimes called visible layer)\n",
    "        \n",
    "        \n",
    "        #Calculates the sigmoid probabilities of input * weights + bias\n",
    "        #Here we multiply the input layer by the weights and add the bias\n",
    "        #This is the phase that creates the hidden layer\n",
    "    def prob_h_given_v(self, visible, w, hb):\n",
    "        return tf.nn.sigmoid(tf.matmul(visible, w) + hb)\n",
    "        \n",
    "        #Calculates the sigmoid probabilities of input * weights + bias\n",
    "        #Here we multiply the hidden layer by the weights and add the input layer bias\n",
    "        #This is the reconstruction phase that recreates the original image from the hidden layer\n",
    "    def prob_v_given_h(self, hidden, w, vb):\n",
    "        return tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w)) + vb)\n",
    "    \n",
    "    #Returns new layer binary values\n",
    "    #This function returns a 0 or 1 based on the sign of the probabilities passed to it\n",
    "    #Our RBM will be utilizing binary features to represent the images\n",
    "    #This function just converts the features we have learned into a binary representation \n",
    "    def sample_prob(self, probs):\n",
    "        return tf.nn.relu(tf.sign(probs - tf.random_uniform(tf.shape(probs))))\n",
    "    def gradient_subtract(self,w,g,lmda,alpha):\n",
    "        \n",
    "        for i in range(w.shape[0]):\n",
    "            for j in range(w.shape[1]):\n",
    "                den1=np.sqrt(np.sum(w[i,:]**2))\n",
    "                print(i,j)\n",
    "                den2=np.sqrt(np.sum(w[:,j]**2))\n",
    "                a=lmda*((g*(w[i,j]/(alpha+den1)))+((1-g)*(w[i,j]/(alpha+den2))))\n",
    "                w[i,j]=w[i,j]-a\n",
    "        return w\n",
    "    def gradient_subtract_improved(self,w,g,lmda,alpha):\n",
    "        b1=np.sqrt(np.sum(w**2,1))\n",
    "        b2=np.sqrt(np.sum(w**2,0))\n",
    "        A1=np.array([b1,]*w.shape[1]).transpose()\n",
    "        A2=np.array([b2,]*w.shape[0])\n",
    "        matSub=lmda*((g*(w/(alpha+A1)))+((1-g)*(w/(alpha+A2))))\n",
    "        return w-matSub\n",
    "        \n",
    "    def train(self, X, teX):\n",
    "        #Initalize placeholder values for graph\n",
    "        #If this looks strange to you, then you have not used Tensorflow before\n",
    "        _w = tf.placeholder(tf.float32, shape = [self.input_size, self.output_size])\n",
    "        _vb = tf.placeholder(tf.float32, shape = [self.input_size])\n",
    "        _hb = tf.placeholder(tf.float32, shape = [self.output_size])\n",
    "        \n",
    "        \n",
    "        #initalize previous variables\n",
    "        #we will be saving the weights of the previous and current iterations\n",
    "        pre_w = np.random.normal(0,0.01, size = [self.input_size,self.output_size])\n",
    "        pre_vb = np.random.normal(0,0.01, size = [self.input_size])\n",
    "        pre_hb = np.random.normal(0,0.01, size = [self.output_size])\n",
    "        \n",
    "        #initalize current variables\n",
    "        #we will be saving the weights of the previous and current iterations\n",
    "        cur_w = np.random.normal(0,0.01, size = [self.input_size,self.output_size])\n",
    "        cur_vb = np.random.normal(0,0.01, size = [self.input_size])\n",
    "        cur_hb = np.random.normal(0,0.01, size = [self.output_size])\n",
    "               \n",
    "        #Plaecholder variable for input layer\n",
    "        v0 = tf.placeholder(tf.float32, shape = [None, self.input_size])\n",
    "         \n",
    "        #pass probabilities of input * w + b into sample prob to get binary values of hidden layer\n",
    "        h0 = self.sample_prob(self.prob_h_given_v(v0, _w, _hb ))\n",
    "        \n",
    "        #pass probabilities of new hidden unit * w + b into sample prob to get new reconstruction\n",
    "        v1 = self.sample_prob(self.prob_v_given_h(h0, _w, _vb))\n",
    "        \n",
    "        #Just get the probailities of the next hidden layer. We wont need the binary values. \n",
    "        #The probabilities here help calculate the gradients during back prop \n",
    "        h1 = self.prob_h_given_v(v1, _w, _hb)\n",
    "        \n",
    "        \n",
    "        #Contrastive Divergence\n",
    "        positive_grad = tf.matmul(tf.transpose(v0), h0) #input' * hidden0\n",
    "        negative_grad = tf.matmul(tf.transpose(v1), h1) #reconstruction' * hidden1\n",
    "        #(pos_grad - neg_grad) / total number of input samples \n",
    "        CD = (positive_grad - negative_grad) / tf.to_float(tf.shape(v0)[0]) \n",
    "        \n",
    "        #This is just the definition of contrastive divergence \n",
    "        update_w1 = _w + self.learning_rate * CD\n",
    "        update_vb = _vb + tf.reduce_mean(v0 - v1, 0)\n",
    "        update_hb = _hb + tf.reduce_mean(h0 - h1, 0)\n",
    "        \n",
    "        \n",
    "        #MSE - This is our error function\n",
    "        err = tf.reduce_mean(tf.square(v0 - v1))\n",
    "        \n",
    "        #Will hold new visible layer.\n",
    "        errors = []\n",
    "        hidden_units = []\n",
    "        reconstruction = []\n",
    "        \n",
    "        test_hidden_units = []\n",
    "        test_reconstruction=[]\n",
    "        \n",
    "        \n",
    "        #The next four lines of code intitalize our Tensorflow graph and create mini batches\n",
    "        #The mini batch code is from cognitive class. I love the way they did this. Just giving credit! \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for epoch in range(self.epochs):\n",
    "                for start, end in zip(range(0, len(X), self.batch_size), range(self.batch_size, len(X), self.batch_size)):\n",
    "                    batch = X[start:end] #Mini batch of images taken from training data\n",
    "                    \n",
    "                    #Feed in batch, previous weights/bias, update weights and store them in current weights\n",
    "                    cur_w1 = sess.run(update_w1, feed_dict = {v0:batch, _w:pre_w , _vb:pre_vb, _hb:pre_hb})\n",
    "                    cur_hb = sess.run(update_hb, feed_dict = {v0:batch, _w:pre_w , _vb:pre_vb, _hb:pre_hb})\n",
    "                    cur_vb = sess.run(update_vb, feed_dict = {v0:batch, _w:pre_w , _vb:pre_vb, _hb:pre_hb})\n",
    "                    cur_w =self.gradient_subtract_improved(cur_w1,0.5,0.0001,0.000000001)\n",
    "\n",
    "                    \n",
    "                    #Save weights \n",
    "                    pre_w = cur_w\n",
    "                    pre_hb = cur_hb\n",
    "                    pre_vb = cur_vb\n",
    "                \n",
    "                #At the end of each iteration, the reconstructed images are stored and the error is outputted \n",
    "                reconstruction.append(sess.run(v1, feed_dict={v0: X, _w: cur_w, _vb: cur_vb, _hb: cur_hb}))        \n",
    "                print('Learning Rate: {}:  Batch Size: {}:  Hidden Layers: {}: Epoch: {}: Error: {}:'.format(self.learning_rate, self.batch_size, \n",
    "                                                                                                             self.output_size, (epoch+1),\n",
    "                                                                                                            sess.run(err, feed_dict={v0: X, _w: cur_w, _vb: cur_vb, _hb: cur_hb})))\n",
    "            \n",
    "            #Store final reconstruction in RBM object\n",
    "            self.new_input_layer = reconstruction[-1]\n",
    "            \n",
    "            # Use the following two blocks of code as per requirement of DAN\n",
    "            # Threshhold the weights DAN_s\n",
    "            low_values_flags1 = np.absolute(pre_w) < 0.05\n",
    "            pre_w[low_values_flags1] = 0\n",
    "            \n",
    "            # Convert in +1 and -1 DAB_b\n",
    "            negative_values = pre_w < 0\n",
    "            pre_w[negative_values] = -1\n",
    "            positive_values = pre_w > 0\n",
    "            pre_w[positive_values] = 1\n",
    "            \n",
    "            \n",
    "            #Store weights in RBM object\n",
    "            self.w = pre_w\n",
    "            self.hb = pre_hb\n",
    "            self.vb = pre_vb\n",
    "    \n",
    "    #This is used for Contrastive Divergence.\n",
    "    #This function makes the reconstruction your new input layer. \n",
    "    def rbm_output(self, X):\n",
    "        input_x = tf.constant(X)\n",
    "        _w = tf.constant(self.w)\n",
    "        _hb = tf.constant(self.hb)\n",
    "        _vb = tf.constant(self.vb)\n",
    "        \n",
    "        out = tf.nn.sigmoid(tf.matmul(input_x, _w) + _hb)\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            return sess.run(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RBM_DBN(object):\n",
    "    def __init__(self, input_size, output_size, learning_rate, batch_size):\n",
    "        self.input_size = input_size #Size of the input layer\n",
    "        self.output_size = output_size #Size of the hidden layer\n",
    "        self.epochs = 5 #How many times we will update the weights \n",
    "        self.learning_rate = learning_rate #How big of a weight update we will perform \n",
    "        self.batch_size = batch_size #How many images will we \"feature engineer\" at at time \n",
    "        self.new_input_layer = None #Initalize new input layer variable for k-step contrastive divergence \n",
    "        self.new_hidden_layer = None\n",
    "        self.new_test_hidden_layer = None\n",
    "        \n",
    "        #Here we initialize the weights and biases of our RBM\n",
    "        #If you are wondering, the 0 is the mean of the distribution we are getting our random weights from. \n",
    "        #The .01 is the standard deviation.\n",
    "        self.w = np.random.normal(0,0.01,[input_size,output_size]) #weights\n",
    "        self.hb = np.random.normal(0,0.01,[output_size]) #hidden layer bias\n",
    "        self.vb = np.random.normal(0,0.01,[input_size]) #input layer bias (sometimes called visible layer)\n",
    "        self.p = np.random.normal(0,0.01,[output_size]) # hidden layer probabilities\n",
    "        \n",
    "        #Calculates the sigmoid probabilities of input * weights + bias\n",
    "        #Here we multiply the input layer by the weights and add the bias\n",
    "        #This is the phase that creates the hidden layer\n",
    "    def prob_h_given_v(self, visible, w, hb):\n",
    "        return tf.nn.sigmoid(tf.matmul(visible, w) + hb)\n",
    "        \n",
    "        #Calculates the sigmoid probabilities of input * weights + bias\n",
    "        #Here we multiply the hidden layer by the weights and add the input layer bias\n",
    "        #This is the reconstruction phase that recreates the original image from the hidden layer\n",
    "    def prob_v_given_h(self, hidden, w, vb):\n",
    "        return tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w)) + vb)\n",
    "    \n",
    "    #Returns new layer binary values\n",
    "    #This function returns a 0 or 1 based on the sign of the probabilities passed to it\n",
    "    #Our RBM will be utilizing binary features to represent the images\n",
    "    #This function just converts the features we have learned into a binary representation \n",
    "    def sample_prob(self, probs):\n",
    "        return tf.nn.relu(tf.sign(probs - tf.random_uniform(tf.shape(probs))))\n",
    "      \n",
    "    def train(self, X, teX):\n",
    "        #Initalize placeholder values for graph\n",
    "        #If this looks strange to you, then you have not used Tensorflow before\n",
    "        _w = tf.placeholder(tf.float32, shape = [self.input_size, self.output_size])\n",
    "        _vb = tf.placeholder(tf.float32, shape = [self.input_size])\n",
    "        _hb = tf.placeholder(tf.float32, shape = [self.output_size])\n",
    "        \n",
    "        \n",
    "        #initalize previous variables\n",
    "        #we will be saving the weights of the previous and current iterations\n",
    "        pre_w = np.random.normal(0,.01, size = [self.input_size,self.output_size])\n",
    "        pre_vb = np.random.normal(0, .01, size = [self.input_size])\n",
    "        pre_hb = np.random.normal(0, .01, size = [self.output_size])\n",
    "        \n",
    "        #initalize current variables\n",
    "        #we will be saving the weights of the previous and current iterations\n",
    "        cur_w = np.random.normal(0, .01, size = [self.input_size,self.output_size])\n",
    "        cur_vb = np.random.normal(0, .01, size = [self.input_size])\n",
    "        cur_hb = np.random.normal(0, .01, size = [self.output_size])\n",
    "               \n",
    "        #Plaecholder variable for input layer\n",
    "        v0 = tf.placeholder(tf.float32, shape = [None, self.input_size])\n",
    "         \n",
    "        #pass probabilities of input * w + b into sample prob to get binary values of hidden layer\n",
    "        h0 = self.sample_prob(self.prob_h_given_v(v0, _w, _hb ))\n",
    "        \n",
    "        #pass probabilities of new hidden unit * w + b into sample prob to get new reconstruction\n",
    "        v1 = self.sample_prob(self.prob_v_given_h(h0, _w, _vb))\n",
    "        \n",
    "        #Just get the probailities of the next hidden layer. We wont need the binary values. \n",
    "        #The probabilities here help calculate the gradients during back prop \n",
    "        h1 = self.prob_h_given_v(v1, _w, _hb)\n",
    "        \n",
    "        \n",
    "        #Contrastive Divergence\n",
    "        positive_grad = tf.matmul(tf.transpose(v0), h0) #input' * hidden0\n",
    "        negative_grad = tf.matmul(tf.transpose(v1), h1) #reconstruction' * hidden1\n",
    "        #(pos_grad - neg_grad) / total number of input samples \n",
    "        CD = (positive_grad - negative_grad) / tf.to_float(tf.shape(v0)[0]) \n",
    "        \n",
    "        #This is just the definition of contrastive divergence \n",
    "        update_w = _w + self.learning_rate * CD\n",
    "        update_vb = _vb + tf.reduce_mean(v0 - v1, 0)\n",
    "        update_hb = _hb + tf.reduce_mean(h0 - h1, 0)\n",
    "        \n",
    "        \n",
    "        #MSE - This is our error function\n",
    "        err = tf.reduce_mean(tf.square(v0 - v1))\n",
    "        \n",
    "        #Will hold new visible layer.\n",
    "        errors = []\n",
    "        hidden_units = []\n",
    "        reconstruction = []\n",
    "        \n",
    "        test_hidden_units = []\n",
    "        test_reconstruction=[]\n",
    "        \n",
    "        \n",
    "        #The next four lines of code intitalize our Tensorflow graph and create mini batches\n",
    "        #The mini batch code is from cognitive class. I love the way they did this. Just giving credit! \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for epoch in range(self.epochs):\n",
    "                for start, end in zip(range(0, len(X), self.batch_size), range(self.batch_size, len(X), self.batch_size)):\n",
    "                    batch = X[start:end] #Mini batch of images taken from training data\n",
    "                    \n",
    "                    #Feed in batch, previous weights/bias, update weights and store them in current weights\n",
    "                    cur_w = sess.run(update_w, feed_dict = {v0:batch, _w:pre_w , _vb:pre_vb, _hb:pre_hb})\n",
    "                    cur_hb = sess.run(update_hb, feed_dict = {v0:batch, _w:pre_w , _vb:pre_vb, _hb:pre_hb})\n",
    "                    cur_vb = sess.run(update_vb, feed_dict = {v0:batch, _w:pre_w , _vb:pre_vb, _hb:pre_hb})\n",
    "                   \n",
    "\n",
    "                    \n",
    "                    #Save weights \n",
    "                    pre_w = cur_w\n",
    "                    pre_hb = cur_hb\n",
    "                    pre_vb = cur_vb\n",
    "                \n",
    "                #At the end of each iteration, the reconstructed images are stored and the error is outputted \n",
    "                reconstruction.append(sess.run(v1, feed_dict={v0: X, _w: cur_w, _vb: cur_vb, _hb: cur_hb}))        \n",
    "                print('Learning Rate: {}:  Batch Size: {}:  Hidden Layers: {}: Epoch: {}: Error: {}:'.format(self.learning_rate, self.batch_size, \n",
    "                                                                                                             self.output_size, (epoch+1),\n",
    "                                                                                                            sess.run(err, feed_dict={v0: X, _w: cur_w, _vb: cur_vb, _hb: cur_hb})))\n",
    "            \n",
    "            #Store final reconstruction in RBM object\n",
    "            self.new_input_layer = reconstruction[-1]\n",
    "            \n",
    "            \n",
    "            \n",
    "            #Store weights in RBM object\n",
    "            self.w = pre_w\n",
    "            self.hb = pre_hb\n",
    "            self.vb = pre_vb\n",
    "    \n",
    "    #This is used for Contrastive Divergence.\n",
    "    #This function makes the reconstruction your new input layer. \n",
    "    def rbm_output(self, X):\n",
    "        input_x = tf.constant(X)\n",
    "        _w = tf.constant(self.w)\n",
    "        _hb = tf.constant(self.hb)\n",
    "        _vb = tf.constant(self.vb)\n",
    "        \n",
    "        out = tf.nn.sigmoid(tf.matmul(input_x, _w) + _hb)\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            return sess.run(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RBM_hidden_size = [800,800] #Three hidden layer sizes for our three layer DBN\n",
    "learning_rate = .01 \n",
    "input_size = trX.shape[1] #input layer size of original image data\n",
    "\n",
    "rbm_dbn_list = [] #This will hold all of the RBMs used in our DBN\n",
    "rbm_dan_list = [] #This will hold all of the RBMS used in our DAN\n",
    "\n",
    "#Creates 3 RBMs\n",
    "for layer in RBM_hidden_size:\n",
    "    rbm_dbn_list.append(RBM_DBN(input_size, layer, learning_rate, 32))\n",
    "    rbm_dan_list.append(RBM_DAN(input_size, layer, learning_rate, 32))\n",
    "    input_size = layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initalize input layer variables \n",
    "inpX1 = trX                \n",
    "test_inpx1 = teX\n",
    "inpX2 = trX\n",
    "test_inpx2 = teX\n",
    "\n",
    "#This loop is the DBN. Each rbm is trained here.\n",
    "#At the end of training, the hidden layer of the RBM is used as input\n",
    "#For the next layer of the DBN.\n",
    "rbm_dbn_troutputs = []\n",
    "rbm_dan_troutputs = []\n",
    "rbm_dbn_teoutputs = []\n",
    "rbm_dan_teoutputs = []\n",
    "for i,rbm in enumerate(rbm_dbn_list):\n",
    "    \n",
    "    print('Input Shape: ', inpX1.shape)\n",
    "    print('Layer: ',(i+1))\n",
    "\n",
    "    rbm.train(inpX1,test_inpx1)\n",
    "    inpX1 = rbm.rbm_output(inpX1)\n",
    "    test_inpx1 = rbm.rbm_output(test_inpx1)\n",
    "    rbm_dbn_troutputs.append(inpX1)\n",
    "    rbm_dbn_teoutputs.append(test_inpx1)\n",
    "\n",
    "    print('Output Shape: ', inpX1.shape)\n",
    "    print()\n",
    "for i,rbm in enumerate(rbm_dan_list):\n",
    "    \n",
    "    print('Input Shape: ', inpX2.shape)\n",
    "    print('Layer: ',(i+1))\n",
    "\n",
    "    rbm.train(inpX2,test_inpx2)\n",
    "    inpX2 = rbm.rbm_output(inpX2)\n",
    "    test_inpx2 = rbm.rbm_output(test_inpx2)\n",
    "    rbm_dan_troutputs.append(inpX2)\n",
    "    rbm_dan_teoutputs.append(test_inpx2)\n",
    "\n",
    "    print('Output Shape: ', inpX2.shape)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving the trained models of DAN and DBN and the test and train sample outputs from DAN and DBN\n",
    "\n",
    "# training set ouput from DAN\n",
    "np.save('rbm_dan_troutput.npy',rbm_dan_troutputs[1]) \n",
    "# testing set output from DAN\n",
    "np.save('rbm_dan_teoutput.npy',rbm_dan_teoutputs[1])\n",
    "# training set output from DBN\n",
    "np.save('rbm_dbn_troutput.npy',rbm_dbn_troutputs[1])\n",
    "# testing set output from DBN\n",
    "np.save('rbm_dbn_teoutput.npy',rbm_dbn_teoutputs[1])\n",
    "# RBMs of DBN\n",
    "np.save('rbm_dbn_list.npy',rbm_dbn_list)\n",
    "# RBMs of DAN\n",
    "np.save('rbm_dan_list.npy',rbm_dan_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot layer 1 weights of DAN and DBN models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "a=np.histogram(rbm_dbn_list[0].w,bins=100)\n",
    "b=np.histogram(rbm_dan_list[0].w,bins=100)\n",
    "indexa=a[1]\n",
    "indexb=b[1]\n",
    "plt.plot(indexa[1:],a[0],'--',label='DBN')\n",
    "plt.plot(indexb[1:],b[0],'r',label='DAN')\n",
    "plt.legend(loc='upper right', shadow=True)\n",
    "plt.title('layer 1 weights')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot layer 2 weights of DAN and DBN models\n",
    "a=np.histogram(rbm_dbn_list[1].w,bins=100)\n",
    "b=np.histogram(rbm_dan_list[1].w,bins=100)\n",
    "indexa=a[1]\n",
    "indexb=b[1]\n",
    "plt.plot(indexa[1:],a[0],'--',label='DBN')\n",
    "plt.plot(indexb[1:],b[0],'r',label='DAN')\n",
    "plt.legend(loc='upper right', shadow=True)\n",
    "plt.title('layer 2 weights')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
